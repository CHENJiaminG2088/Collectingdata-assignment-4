{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/programminghistorian/jekyll/blob/Issue-3052/assets/corpus-analysis-with-spacy/corpus-analysis-with-spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVeD4Ik7D43F"
   },
   "source": [
    "# Corpus Analysis with spaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ8ve667EvxG"
   },
   "source": [
    "### Installing, Importing and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spaCy in /Users/meinv/anaconda3/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spaCy) (1.24.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spaCy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spaCy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spaCy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spaCy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jinja2->spaCy) (2.1.1)\n",
      "Requirement already satisfied: plotly in /Users/meinv/anaconda3/lib/python3.11/site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: nbformat in /Users/meinv/anaconda3/lib/python3.11/site-packages (5.9.2)\n",
      "Requirement already satisfied: fastjsonschema in /Users/meinv/anaconda3/lib/python3.11/site-packages (from nbformat) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from nbformat) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in /Users/meinv/anaconda3/lib/python3.11/site-packages (from nbformat) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from nbformat) (5.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jupyter-core->nbformat) (3.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install spaCy\n",
    "!pip install plotly\n",
    "%pip install nbformat --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KlvUa2oX1645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "!spacy download en_core_web_sm\n",
    "\n",
    "import os\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  \n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ub8MflGfA_HB"
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "file_names = []\n",
    "\n",
    "for _file_name in os.listdir('rap_lyrics'):\n",
    "    if _file_name.endswith('.txt'):   \n",
    "        texts.append(open('rap_lyrics' + '/' + _file_name, 'r', encoding='latin-1').read())        \n",
    "        file_names.append(_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Z7BmHGFBA_HB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'Filename':file_names,'Text':texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "yC5-sbOPA_HB"
   },
   "outputs": [],
   "source": [
    "lyrics_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "cK3PvJkcA_HC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>\\nWe sell crack to our own out the back of our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>\\nLove ain't for the faint of heart\\nStart tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>\\nWell, it is a weepin' and a moanin' and a gn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>\\nÂ­\\n\\nLet me give you a little inside inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\\n\"Look, I was gonna go easy on you, and not t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \n",
       "0  \\nWe sell crack to our own out the back of our...  \n",
       "1  \\nLove ain't for the faint of heart\\nStart tra...  \n",
       "2  \\nWell, it is a weepin' and a moanin' and a gn...  \n",
       "3  \\nÂ­\\n\\nLet me give you a little inside inform...  \n",
       "4  \\n\"Look, I was gonna go easy on you, and not t...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "kax8Ecu7A_HC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \n",
       "0  We sell crack to our own out the back of our h...  \n",
       "1  Love ain't for the faint of heart Start traini...  \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...  \n",
       "3  Â­ Let me give you a little inside information...  \n",
       "4  \"Look, I was gonna go easy on you, and not to ...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df['Text'] = lyrics_df['Text'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "zGbZVIrFA_HC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli</td>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists</td>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar</td>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem</td>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Artist                        File\n",
       "0      Talib Kweli      Talib Kweli_lyrics.txt\n",
       "1  CunninLynguists  CunninLynguists_lyrics.txt\n",
       "2       Kanye West       Kanye West_lyrics.txt\n",
       "3    Deniro Farrar    Deniro Farrar_lyrics.txt\n",
       "4           Eminem           Eminem_lyrics.txt"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv('metadata.csv')\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "RO4lwuwJcrID"
   },
   "outputs": [],
   "source": [
    "lyrics_df['Filename'] = lyrics_df['Filename'].str.replace('.txt', '', regex=True)\n",
    "\n",
    "metadata_df.rename(columns={\"lyrics ID\": \"Filename\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Artist', 'File'], dtype='object')\n",
      "Index(['Filename', 'Text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(metadata_df.columns)\n",
    "print(lyrics_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "2eCYbDExeuqM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = metadata_df.merge(lyrics_df, left_on='File', right_on='Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "C-8mOPIZA_HD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Filename                                               Text\n",
       "0      Talib Kweli_lyrics  We sell crack to our own out the back of our h...\n",
       "1  CunninLynguists_lyrics  Love ain't for the faint of heart Start traini...\n",
       "2       Kanye West_lyrics  Well, it is a weepin' and a moanin' and a gnas...\n",
       "3    Deniro Farrar_lyrics  Â­ Let me give you a little inside information...\n",
       "4           Eminem_lyrics  \"Look, I was gonna go easy on you, and not to ..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdlHoqlBA_HD"
   },
   "source": [
    "## Text Enrichment with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSNTL5msA_HE"
   },
   "source": [
    "### Text Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "SBEb3CErA_HE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[We, sell, crack, to, our, own, out, the, back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[Love, ai, n't, for, the, faint, of, heart, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[Well, ,, it, is, a, weepin, ', and, a, moanin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[Â­, Let, me, give, you, a, little, inside, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[\", Look, ,, I, was, gon, na, go, easy, on, yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Filename                                               Text  \\\n",
       "0      Talib Kweli_lyrics  We sell crack to our own out the back of our h...   \n",
       "1  CunninLynguists_lyrics  Love ain't for the faint of heart Start traini...   \n",
       "2       Kanye West_lyrics  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3    Deniro Farrar_lyrics  Â­ Let me give you a little inside information...   \n",
       "4           Eminem_lyrics  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [We, sell, crack, to, our, own, out, the, back...  \n",
       "1  [Love, ai, n't, for, the, faint, of, heart, St...  \n",
       "2  [Well, ,, it, is, a, weepin, ', and, a, moanin...  \n",
       "3  [Â­, Let, me, give, you, a, little, inside, in...  \n",
       "4  [\", Look, ,, I, was, gon, na, go, easy, on, yo...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_token(lyrics_text):\n",
    "    \n",
    "    doc = nlp(lyrics_text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "lyrics_df['Tokens'] = lyrics_df['Text'].apply(get_token)\n",
    "\n",
    "lyrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "xSU8Rn57FbSK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[We, sell, crack, to, our, own, out, the, back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[Love, ai, n't, for, the, faint, of, heart, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[Well, ,, it, is, a, weepin, ', and, a, moanin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[Â­, Let, me, give, you, a, little, inside, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[\", Look, ,, I, was, gon, na, go, easy, on, yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  We sell crack to our own out the back of our h...   \n",
       "1  Love ain't for the faint of heart Start traini...   \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3  Â­ Let me give you a little inside information...   \n",
       "4  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [We, sell, crack, to, our, own, out, the, back...  \n",
       "1  [Love, ai, n't, for, the, faint, of, heart, St...  \n",
       "2  [Well, ,, it, is, a, weepin, ', and, a, moanin...  \n",
       "3  [Â­, Let, me, give, you, a, little, inside, in...  \n",
       "4  [\", Look, ,, I, was, gon, na, go, easy, on, yo...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = lyrics_df[['Text', 'Tokens']].copy()\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLzPDKXqA_HF"
   },
   "source": [
    "#### Lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"money\" appears in the text tokens column 242 times.\n",
      "\"money\" appears in the lemmas column 587 times.\n"
     ]
    }
   ],
   "source": [
    "def get_lemma(tokens):\n",
    "    lemmas = [token.lemma_ for token in nlp(' '.join(tokens))]\n",
    "    return lemmas\n",
    "\n",
    "lyrics_df['Lemmas'] = lyrics_df['Tokens'].apply(get_lemma)\n",
    "\n",
    "print(f'\"money\" appears in the text tokens column ' + str(lyrics_df['Tokens'].apply(lambda x: x.count('write')).sum()) + ' times.')\n",
    "print(f'\"money\" appears in the lemmas column ' + str(lyrics_df['Lemmas'].apply(lambda x: x.count('write')).sum()) + ' times.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvH1xTvZ3-MW"
   },
   "source": [
    "### Text Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  We sell crack to our own out the back of our h...   \n",
       "1  Love ain't for the faint of heart Start traini...   \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3  Â­ Let me give you a little inside information...   \n",
       "4  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                                 POS  \n",
       "0  [(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...  \n",
       "1  [(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...  \n",
       "2  [(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...  \n",
       "3  [(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...  \n",
       "4  [(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df = pd.DataFrame(d)\n",
    "\n",
    "lyrics_df['Text'] = lyrics_df['Text'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "\n",
    "def process_batch(texts):    \n",
    "    results = []\n",
    "\n",
    "    for text in texts:        \n",
    "        doc = nlp(text)                \n",
    "        pos_tags = [(token.pos_, token.tag_) for token in doc]\n",
    "               \n",
    "        results.append(pos_tags)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "num_batches = len(lyrics_df) // batch_size + 1\n",
    "final_results = []\n",
    "\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(lyrics_df))\n",
    "        \n",
    "    current_batch = lyrics_df['Text'].iloc[start_idx:end_idx]\n",
    "\n",
    "    batch_results = process_batch(current_batch)\n",
    "    \n",
    "\n",
    "    final_results.extend(batch_results)\n",
    "\n",
    "\n",
    "lyrics_df['POS'] = final_results\n",
    "\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39utqaRyh_M1"
   },
   "source": [
    "#### Named Entity Recognition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "wRffhMlUA_HI",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL : Numerals that do not fall under another type\n",
      "DATE : Absolute or relative dates or periods\n",
      "EVENT : Named hurricanes, battles, wars, sports events, etc.\n",
      "FAC : Buildings, airports, highways, bridges, etc.\n",
      "GPE : Countries, cities, states\n",
      "LANGUAGE : Any named language\n",
      "LAW : Named documents made into laws.\n",
      "LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "MONEY : Monetary values, including unit\n",
      "NORP : Nationalities or religious or political groups\n",
      "ORDINAL : \"first\", \"second\", etc.\n",
      "ORG : Companies, agencies, institutions, etc.\n",
      "PERCENT : Percentage, including \"%\"\n",
      "PERSON : People, including fictional\n",
      "PRODUCT : Objects, vehicles, foods, etc. (not services)\n",
      "QUANTITY : Measurements, as of weight or distance\n",
      "TIME : Times smaller than a day\n",
      "WORK_OF_ART : Titles of books, songs, etc.\n"
     ]
    }
   ],
   "source": [
    "labels = nlp.get_pipe(\"ner\").labels\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    print(label + ' : ' + spacy.explain(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>Sentiment_Analysis</th>\n",
       "      <th>Named_Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...</td>\n",
       "      <td>0.080774</td>\n",
       "      <td>[(the Clones Work ', ORG), (Norman Mailer Mi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>[(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>[(Believe, ORG), (two, CARDINAL), (Lambo, PERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...</td>\n",
       "      <td>-0.029976</td>\n",
       "      <td>[(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...</td>\n",
       "      <td>-0.033670</td>\n",
       "      <td>[(one, CARDINAL), (Six minutes, TIME), (Six mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  We sell crack to our own out the back of our h...   \n",
       "1  Love ain't for the faint of heart Start traini...   \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3  Â­ Let me give you a little inside information...   \n",
       "4  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                                 POS  Sentiment_Analysis  \\\n",
       "0  [(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...            0.080774   \n",
       "1  [(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...            0.040427   \n",
       "2  [(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...            0.047397   \n",
       "3  [(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...           -0.029976   \n",
       "4  [(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...           -0.033670   \n",
       "\n",
       "                                      Named_Entities  \n",
       "0  [(the Clones Work ', ORG), (Norman Mailer Mi, ...  \n",
       "1  [(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...  \n",
       "2  [(Believe, ORG), (two, CARDINAL), (Lambo, PERS...  \n",
       "3  [(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...  \n",
       "4  [(one, CARDINAL), (Six minutes, TIME), (Six mi...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "lyrics_df['Named_Entities'] = lyrics_df['Text'].apply(extract_named_entities)\n",
    "\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>Sentiment_Analysis</th>\n",
       "      <th>Named_Entities</th>\n",
       "      <th>Identified_Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...</td>\n",
       "      <td>0.080774</td>\n",
       "      <td>[(the Clones Work ', ORG), (Norman Mailer Mi, ...</td>\n",
       "      <td>[the, Clones, Work, ', Norman, Mailer, Mi, thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>[(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...</td>\n",
       "      <td>[Visits, Love, Love'll, Brain, Studderin, four...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>[(Believe, ORG), (two, CARDINAL), (Lambo, PERS...</td>\n",
       "      <td>[Believe, two, Lambo, two, Lambo, Lamborghini,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...</td>\n",
       "      <td>-0.029976</td>\n",
       "      <td>[(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...</td>\n",
       "      <td>[Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...</td>\n",
       "      <td>-0.033670</td>\n",
       "      <td>[(one, CARDINAL), (Six minutes, TIME), (Six mi...</td>\n",
       "      <td>[one, Six, minutes, Six, minutes, Slim, Shady,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  We sell crack to our own out the back of our h...   \n",
       "1  Love ain't for the faint of heart Start traini...   \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3  Â­ Let me give you a little inside information...   \n",
       "4  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                                 POS  Sentiment_Analysis  \\\n",
       "0  [(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...            0.080774   \n",
       "1  [(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...            0.040427   \n",
       "2  [(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...            0.047397   \n",
       "3  [(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...           -0.029976   \n",
       "4  [(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...           -0.033670   \n",
       "\n",
       "                                      Named_Entities  \\\n",
       "0  [(the Clones Work ', ORG), (Norman Mailer Mi, ...   \n",
       "1  [(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...   \n",
       "2  [(Believe, ORG), (two, CARDINAL), (Lambo, PERS...   \n",
       "3  [(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...   \n",
       "4  [(one, CARDINAL), (Six minutes, TIME), (Six mi...   \n",
       "\n",
       "                                 Identified_Entities  \n",
       "0  [the, Clones, Work, ', Norman, Mailer, Mi, thr...  \n",
       "1  [Visits, Love, Love'll, Brain, Studderin, four...  \n",
       "2  [Believe, two, Lambo, two, Lambo, Lamborghini,...  \n",
       "3  [Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...  \n",
       "4  [one, Six, minutes, Six, minutes, Slim, Shady,...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_identified_entities(text):\n",
    "    doc = nlp(text)\n",
    "        \n",
    "    identified_entities = [token.text for token in doc if token.ent_type_]\n",
    "    \n",
    "    return identified_entities\n",
    "\n",
    "lyrics_df['Identified_Entities'] = lyrics_df['Text'].apply(extract_identified_entities)\n",
    "\n",
    "\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>Sentiment_Analysis</th>\n",
       "      <th>Named_Entities</th>\n",
       "      <th>Identified_Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...</td>\n",
       "      <td>0.080774</td>\n",
       "      <td>[(the Clones Work ', ORG), (Norman Mailer Mi, ...</td>\n",
       "      <td>[the, Clones, Work, ', Norman, Mailer, Mi, thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>[(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...</td>\n",
       "      <td>[Visits, Love, Love'll, Brain, Studderin, four...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>[(Believe, ORG), (two, CARDINAL), (Lambo, PERS...</td>\n",
       "      <td>[Believe, two, Lambo, two, Lambo, Lamborghini,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...</td>\n",
       "      <td>-0.029976</td>\n",
       "      <td>[(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...</td>\n",
       "      <td>[Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...</td>\n",
       "      <td>-0.033670</td>\n",
       "      <td>[(one, CARDINAL), (Six minutes, TIME), (Six mi...</td>\n",
       "      <td>[one, Six, minutes, Six, minutes, Slim, Shady,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  We sell crack to our own out the back of our h...   \n",
       "1  Love ain't for the faint of heart Start traini...   \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3  Â­ Let me give you a little inside information...   \n",
       "4  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                                 POS  Sentiment_Analysis  \\\n",
       "0  [(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...            0.080774   \n",
       "1  [(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...            0.040427   \n",
       "2  [(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...            0.047397   \n",
       "3  [(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...           -0.029976   \n",
       "4  [(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...           -0.033670   \n",
       "\n",
       "                                      Named_Entities  \\\n",
       "0  [(the Clones Work ', ORG), (Norman Mailer Mi, ...   \n",
       "1  [(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...   \n",
       "2  [(Believe, ORG), (two, CARDINAL), (Lambo, PERS...   \n",
       "3  [(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...   \n",
       "4  [(one, CARDINAL), (Six minutes, TIME), (Six mi...   \n",
       "\n",
       "                                 Identified_Entities  \n",
       "0  [the, Clones, Work, ', Norman, Mailer, Mi, thr...  \n",
       "1  [Visits, Love, Love'll, Brain, Studderin, four...  \n",
       "2  [Believe, two, Lambo, two, Lambo, Lamborghini,...  \n",
       "3  [Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...  \n",
       "4  [one, Six, minutes, Six, minutes, Slim, Shady,...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def perform_sentiment_analysis(text):\n",
    "    \n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    \n",
    "    sentiment_polarity = blob.sentiment.polarity\n",
    "    \n",
    "    return sentiment_polarity\n",
    "\n",
    "\n",
    "lyrics_df['Sentiment_Analysis'] = lyrics_df['Text'].apply(perform_sentiment_analysis)\n",
    "\n",
    "lyrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>Sentiment_Analysis</th>\n",
       "      <th>Named_Entities</th>\n",
       "      <th>Identified_Entities</th>\n",
       "      <th>Most_Frequent_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...</td>\n",
       "      <td>0.080774</td>\n",
       "      <td>[(the Clones Work ', ORG), (Norman Mailer Mi, ...</td>\n",
       "      <td>[the, Clones, Work, ', Norman, Mailer, Mi, thr...</td>\n",
       "      <td>[the, you, to, it, and, of, in, we, like, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>[(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...</td>\n",
       "      <td>[Visits, Love, Love'll, Brain, Studderin, four...</td>\n",
       "      <td>[the, to, and, you, in, my, it, of, that, with]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>[(Believe, ORG), (two, CARDINAL), (Lambo, PERS...</td>\n",
       "      <td>[Believe, two, Lambo, two, Lambo, Lamborghini,...</td>\n",
       "      <td>[the, you, and, to, it, that, my, me, in, all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...</td>\n",
       "      <td>-0.029976</td>\n",
       "      <td>[(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...</td>\n",
       "      <td>[Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...</td>\n",
       "      <td>[the, my, to, and, you, me, nigga, it, in, that]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...</td>\n",
       "      <td>-0.033670</td>\n",
       "      <td>[(one, CARDINAL), (Six minutes, TIME), (Six mi...</td>\n",
       "      <td>[one, Six, minutes, Six, minutes, Slim, Shady,...</td>\n",
       "      <td>[you, the, to, and, it, my, me, in, that, of]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  We sell crack to our own out the back of our h...   \n",
       "1  Love ain't for the faint of heart Start traini...   \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3  Â­ Let me give you a little inside information...   \n",
       "4  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                                 POS  Sentiment_Analysis  \\\n",
       "0  [(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...            0.080774   \n",
       "1  [(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...            0.040427   \n",
       "2  [(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...            0.047397   \n",
       "3  [(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...           -0.029976   \n",
       "4  [(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...           -0.033670   \n",
       "\n",
       "                                      Named_Entities  \\\n",
       "0  [(the Clones Work ', ORG), (Norman Mailer Mi, ...   \n",
       "1  [(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...   \n",
       "2  [(Believe, ORG), (two, CARDINAL), (Lambo, PERS...   \n",
       "3  [(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...   \n",
       "4  [(one, CARDINAL), (Six minutes, TIME), (Six mi...   \n",
       "\n",
       "                                 Identified_Entities  \\\n",
       "0  [the, Clones, Work, ', Norman, Mailer, Mi, thr...   \n",
       "1  [Visits, Love, Love'll, Brain, Studderin, four...   \n",
       "2  [Believe, two, Lambo, two, Lambo, Lamborghini,...   \n",
       "3  [Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...   \n",
       "4  [one, Six, minutes, Six, minutes, Slim, Shady,...   \n",
       "\n",
       "                                Most_Frequent_Words  \n",
       "0     [the, you, to, it, and, of, in, we, like, is]  \n",
       "1   [the, to, and, you, in, my, it, of, that, with]  \n",
       "2    [the, you, and, to, it, that, my, me, in, all]  \n",
       "3  [the, my, to, and, you, me, nigga, it, in, that]  \n",
       "4     [you, the, to, and, it, my, me, in, that, of]  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "def most_frequent_words_analysis(text):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    \n",
    "    X = vectorizer.fit_transform([text])\n",
    "    \n",
    "  \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    word_counts = X.toarray().flatten()\n",
    "    \n",
    "    word_counts_dict = dict(zip(feature_names, word_counts))\n",
    "    \n",
    "    sorted_word_counts = sorted(word_counts_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    most_frequent_words = [word for word, count in sorted_word_counts[:10]]  # Adjust the number as needed\n",
    "    \n",
    "    return most_frequent_words\n",
    "\n",
    "lyrics_df['Most_Frequent_Words'] = lyrics_df['Text'].apply(most_frequent_words_analysis)\n",
    "\n",
    "lyrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>Sentiment_Analysis</th>\n",
       "      <th>Named_Entities</th>\n",
       "      <th>Identified_Entities</th>\n",
       "      <th>Most_Frequent_Words</th>\n",
       "      <th>Lyrics_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talib Kweli_lyrics.txt</td>\n",
       "      <td>We sell crack to our own out the back of our h...</td>\n",
       "      <td>[(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...</td>\n",
       "      <td>0.080774</td>\n",
       "      <td>[(the Clones Work ', ORG), (Norman Mailer Mi, ...</td>\n",
       "      <td>[the, Clones, Work, ', Norman, Mailer, Mi, thr...</td>\n",
       "      <td>[the, you, to, it, and, of, in, we, like, is]</td>\n",
       "      <td>194625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CunninLynguists_lyrics.txt</td>\n",
       "      <td>Love ain't for the faint of heart Start traini...</td>\n",
       "      <td>[(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>[(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...</td>\n",
       "      <td>[Visits, Love, Love'll, Brain, Studderin, four...</td>\n",
       "      <td>[the, to, and, you, in, my, it, of, that, with]</td>\n",
       "      <td>156635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanye West_lyrics.txt</td>\n",
       "      <td>Well, it is a weepin' and a moanin' and a gnas...</td>\n",
       "      <td>[(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>[(Believe, ORG), (two, CARDINAL), (Lambo, PERS...</td>\n",
       "      <td>[Believe, two, Lambo, two, Lambo, Lamborghini,...</td>\n",
       "      <td>[the, you, and, to, it, that, my, me, in, all]</td>\n",
       "      <td>183625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deniro Farrar_lyrics.txt</td>\n",
       "      <td>Â­ Let me give you a little inside information...</td>\n",
       "      <td>[(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...</td>\n",
       "      <td>-0.029976</td>\n",
       "      <td>[(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...</td>\n",
       "      <td>[Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...</td>\n",
       "      <td>[the, my, to, and, you, me, nigga, it, in, that]</td>\n",
       "      <td>151715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eminem_lyrics.txt</td>\n",
       "      <td>\"Look, I was gonna go easy on you, and not to ...</td>\n",
       "      <td>[(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...</td>\n",
       "      <td>-0.033670</td>\n",
       "      <td>[(one, CARDINAL), (Six minutes, TIME), (Six mi...</td>\n",
       "      <td>[one, Six, minutes, Six, minutes, Slim, Shady,...</td>\n",
       "      <td>[you, the, to, and, it, my, me, in, that, of]</td>\n",
       "      <td>290335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Filename  \\\n",
       "0      Talib Kweli_lyrics.txt   \n",
       "1  CunninLynguists_lyrics.txt   \n",
       "2       Kanye West_lyrics.txt   \n",
       "3    Deniro Farrar_lyrics.txt   \n",
       "4           Eminem_lyrics.txt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  We sell crack to our own out the back of our h...   \n",
       "1  Love ain't for the faint of heart Start traini...   \n",
       "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
       "3  Â­ Let me give you a little inside information...   \n",
       "4  \"Look, I was gonna go easy on you, and not to ...   \n",
       "\n",
       "                                                 POS  Sentiment_Analysis  \\\n",
       "0  [(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...            0.080774   \n",
       "1  [(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...            0.040427   \n",
       "2  [(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...            0.047397   \n",
       "3  [(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...           -0.029976   \n",
       "4  [(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...           -0.033670   \n",
       "\n",
       "                                      Named_Entities  \\\n",
       "0  [(the Clones Work ', ORG), (Norman Mailer Mi, ...   \n",
       "1  [(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...   \n",
       "2  [(Believe, ORG), (two, CARDINAL), (Lambo, PERS...   \n",
       "3  [(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...   \n",
       "4  [(one, CARDINAL), (Six minutes, TIME), (Six mi...   \n",
       "\n",
       "                                 Identified_Entities  \\\n",
       "0  [the, Clones, Work, ', Norman, Mailer, Mi, thr...   \n",
       "1  [Visits, Love, Love'll, Brain, Studderin, four...   \n",
       "2  [Believe, two, Lambo, two, Lambo, Lamborghini,...   \n",
       "3  [Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...   \n",
       "4  [one, Six, minutes, Six, minutes, Slim, Shady,...   \n",
       "\n",
       "                                Most_Frequent_Words  Lyrics_Length  \n",
       "0     [the, you, to, it, and, of, in, we, like, is]         194625  \n",
       "1   [the, to, and, you, in, my, it, of, that, with]         156635  \n",
       "2    [the, you, and, to, it, that, my, me, in, all]         183625  \n",
       "3  [the, my, to, and, you, me, nigga, it, in, that]         151715  \n",
       "4     [you, the, to, and, it, my, me, in, that, of]         290335  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df['Lyrics_Length'] = lyrics_df['Text'].apply(len)\n",
    "\n",
    "lyrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata_df = pd.read_csv('metadata.csv')\n",
    "\n",
    "new_column_data = metadata_df['Artist']\n",
    "\n",
    "lyrics_df.insert(1, 'Artist', new_column_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Filename           Artist  \\\n",
      "0      Talib Kweli_lyrics.txt      Talib Kweli   \n",
      "1  CunninLynguists_lyrics.txt  CunninLynguists   \n",
      "2       Kanye West_lyrics.txt       Kanye West   \n",
      "3    Deniro Farrar_lyrics.txt    Deniro Farrar   \n",
      "4           Eminem_lyrics.txt           Eminem   \n",
      "\n",
      "                                                Text  \\\n",
      "0  We sell crack to our own out the back of our h...   \n",
      "1  Love ain't for the faint of heart Start traini...   \n",
      "2  Well, it is a weepin' and a moanin' and a gnas...   \n",
      "3  Â­ Let me give you a little inside information...   \n",
      "4  \"Look, I was gonna go easy on you, and not to ...   \n",
      "\n",
      "                                                 POS  Sentiment_Analysis  \\\n",
      "0  [(PRON, PRP), (VERB, VBP), (NOUN, NN), (ADP, I...            0.080774   \n",
      "1  [(NOUN, NN), (VERB, VBP), (PART, RB), (ADP, IN...            0.040427   \n",
      "2  [(INTJ, UH), (PUNCT, ,), (PRON, PRP), (AUX, VB...            0.047397   \n",
      "3  [(INTJ, UH), (VERB, VB), (PRON, PRP), (VERB, V...           -0.029976   \n",
      "4  [(PUNCT, ``), (VERB, VB), (PUNCT, ,), (PRON, P...           -0.033670   \n",
      "\n",
      "                                      Named_Entities  \\\n",
      "0  [(the Clones Work ', ORG), (Norman Mailer Mi, ...   \n",
      "1  [(Visits, PRODUCT), (Love, WORK_OF_ART), (Love...   \n",
      "2  [(Believe, ORG), (two, CARDINAL), (Lambo, PERS...   \n",
      "3  [(Nigga, PERSON), (36, CARDINAL), (OG, ORG), (...   \n",
      "4  [(one, CARDINAL), (Six minutes, TIME), (Six mi...   \n",
      "\n",
      "                                 Identified_Entities  \\\n",
      "0  [the, Clones, Work, ', Norman, Mailer, Mi, thr...   \n",
      "1  [Visits, Love, Love'll, Brain, Studderin, four...   \n",
      "2  [Believe, two, Lambo, two, Lambo, Lamborghini,...   \n",
      "3  [Nigga, 36, OG, Nigga, 16, Nigga, Denzel, Univ...   \n",
      "4  [one, Six, minutes, Six, minutes, Slim, Shady,...   \n",
      "\n",
      "                                Most_Frequent_Words  Lyrics_Length  \n",
      "0     [the, you, to, it, and, of, in, we, like, is]         194625  \n",
      "1   [the, to, and, you, in, my, it, of, that, with]         156635  \n",
      "2    [the, you, and, to, it, that, my, me, in, all]         183625  \n",
      "3  [the, my, to, and, you, me, nigga, it, in, that]         151715  \n",
      "4     [you, the, to, and, it, my, me, in, that, of]         290335  \n"
     ]
    }
   ],
   "source": [
    "print(lyrics_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKiNOMoDB2ta"
   },
   "source": [
    "### Download Enriched Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='raplyrics_with_tags.csv' target='_blank'>raplyrics_with_tags.csv</a><br>"
      ],
      "text/plain": [
       "/Users/meinv/Documents/collecting data week 5/corpus-analysis-spacy-main/raplyrics_with_tags.csv"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "lyrics_df.to_csv('raplyrics_with_tags.csv', index=False)\n",
    "\n",
    "FileLink(r'raplyrics_with_tags.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
